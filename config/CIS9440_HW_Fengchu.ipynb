{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdFah--xo4m7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bdFah--xo4m7",
    "outputId": "fe35d659-8905-45c1-e261-c725ef26d381"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-storage-blob in c:\\users\\andrea\\anaconda3\\lib\\site-packages (12.19.1)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.28.0 in c:\\users\\andrea\\anaconda3\\lib\\site-packages (from azure-storage-blob) (1.30.1)\n",
      "Requirement already satisfied: isodate>=0.6.1 in c:\\users\\andrea\\anaconda3\\lib\\site-packages (from azure-storage-blob) (0.6.1)\n",
      "Requirement already satisfied: cryptography>=2.1.4 in c:\\users\\andrea\\anaconda3\\lib\\site-packages (from azure-storage-blob) (39.0.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\andrea\\anaconda3\\lib\\site-packages (from azure-storage-blob) (4.7.1)\n",
      "Requirement already satisfied: requests>=2.21.0 in c:\\users\\andrea\\anaconda3\\lib\\site-packages (from azure-core<2.0.0,>=1.28.0->azure-storage-blob) (2.31.0)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\andrea\\anaconda3\\lib\\site-packages (from azure-core<2.0.0,>=1.28.0->azure-storage-blob) (1.16.0)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\andrea\\anaconda3\\lib\\site-packages (from cryptography>=2.1.4->azure-storage-blob) (1.15.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\andrea\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\andrea\\anaconda3\\lib\\site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.28.0->azure-storage-blob) (3.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\andrea\\anaconda3\\lib\\site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.28.0->azure-storage-blob) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\andrea\\anaconda3\\lib\\site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.28.0->azure-storage-blob) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\andrea\\anaconda3\\lib\\site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.28.0->azure-storage-blob) (1.26.14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\andrea\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\andrea\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\andrea\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\andrea\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\andrea\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\andrea\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install azure-storage-blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f73fc0dc",
   "metadata": {
    "id": "f73fc0dc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "from azure.storage.blob import BlobServiceClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b47e317",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 869
    },
    "id": "4b47e317",
    "outputId": "7d2a5a82-cf81-4f49-a2de-800aca4ef076",
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22340\\2225233705.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig_file_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"r\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mconfig_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mconnection_string\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"connectionString\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[0mcls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m         \u001b[0mparse_float\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparse_float\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparse_int\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparse_int\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m         parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n\u001b[0m\u001b[0;32m    297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mloads\u001b[1;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    346\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[1;32m--> 348\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    349\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m         \"\"\"\n\u001b[1;32m--> 337\u001b[1;33m         \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Expecting value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from io import StringIO\n",
    "\n",
    "\n",
    "# Your Azure Storage connection details\n",
    "config_file_path = \"config.json\"\n",
    "\n",
    "with open(config_file_path,\"r\") as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "connection_string = config[\"connectionString\"]\n",
    "container_name = \"violation\"\n",
    "\n",
    "# Initialize the Azure Blob service client\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "container_client = blob_service_client.get_container_client(container_name)\n",
    "\n",
    "# Base URL for your data source\n",
    "base_url = \"https://data.cityofnewyork.us/resource/nc67-uf89.csv\"\n",
    "\n",
    "# Parameters for API request and batch processing\n",
    "limit = 10000\n",
    "total_records = 111625885\n",
    "offset = 0  # Start from the beginning if you aim to download the entire dataset\n",
    "\n",
    "# Dataframe to accumulate records\n",
    "accumulated_df = pd.DataFrame()\n",
    "\n",
    "while offset < total_records:\n",
    "    # Update the URL with the current offset\n",
    "    data_url = f\"{base_url}?$limit={limit}&$offset={offset}\"\n",
    "\n",
    "    try:\n",
    "        # Download the current chunk of data\n",
    "        df_chunk = pd.read_csv(data_url)\n",
    "\n",
    "        # Accumulate the data\n",
    "        accumulated_df = pd.concat([accumulated_df, df_chunk], ignore_index=True)\n",
    "\n",
    "        # Check if accumulated data reached the batch size of 50,000 records or if it's the last chunk\n",
    "        if len(accumulated_df) >= 50000 or offset + limit >= total_records:\n",
    "            # Convert the accumulated DataFrame to a CSV string\n",
    "            csv_data = StringIO()\n",
    "            accumulated_df.to_csv(csv_data, index=False)\n",
    "            csv_data.seek(0)\n",
    "\n",
    "            # Define the blob name in your container\n",
    "            blob_name = f\"data_chunk_offset_{offset}.csv\"\n",
    "\n",
    "            # Upload the batch to Azure Blob Storage\n",
    "            blob_client = container_client.get_blob_client(blob_name)\n",
    "            blob_client.upload_blob(csv_data.getvalue(), overwrite=True)\n",
    "            print(f\"Successfully uploaded {blob_name}\")\n",
    "\n",
    "            # Reset the accumulated dataframe\n",
    "            accumulated_df = pd.DataFrame()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during data fetch/upload: {e}\")\n",
    "        break  # or handle retry logic\n",
    "\n",
    "    # Increment the offset for the next loop iteration\n",
    "    offset += limit\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
